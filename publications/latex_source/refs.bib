@techreport{influx,
author = {Paul Dix},
institution = {InfluxData},
title = {What is Time Series Data?},
year = {2024},
url = {https://www.influxdata.com/what-is-time-series-data/},
}
@article{gorilla,
author = {Teller, J. and others},
journal = {Proceedings of the VLDB Endowment},
number = {12},
pages = {1816-1827},
title = {Gorilla: A Fast, Scalable, In-Memory Time Series Database},
volume = {8},
year = {2015},
}
@techreport{victoria,
author = {Aliaksandr Valialkin},
institution = {VictoriaMetrics},
month = {May},
title = {Achieving Better Compression for Time Series Data than Gorilla.},
year = {2019},
url = {https://faun.pub/victoriametrics-achieving-better-compression-for-time-series-data-than-gorilla-317bc1f95932},
}
@techreport{timescale,
author = {Joshua and Lockerman and Ajay Kulkarni},
institution = {TimeScale},
month = {April},
title = {Time Series Compression Algorithms Explained},
year = {2020},
url = {https://www.timescale.com/blog/time-series-compression-algorithms-explained/},
}
@techreport{dzone,
author = {Rosana de Oliveira Gomes},
institution = {DZone},
month = {September},
title = {Time Series Compression Algorithms and Their Applications},
year = {2022},
url = {https://dzone.com/articles/time-series-compression-algorithms-and-their-appli},
}
@techreport{compression,
author = {Hongze Cheng},
institution = {TDEngine},
title = {Compressing Time Series Data},
year = {2022},
month = {October},
url = {https://tdengine.com/compressing-time-series-data/#Time_Series_Compression},
}
@techreport{monitoring-samples,
author = {Alexis Lê-Quôc},
institution = {Datadog},
title = {Monitoring 101: Collecting the right data},
year = {2015},
month = {June},
url = {https://www.datadoghq.com/blog/monitoring-101-collecting-data/},
}
@techreport{nasa-compression,
author = {S. Edward Hawkins III and Edward Hugo Darlington},
institution = {Johns Hopkins University Applied Physics Laboratory for Goddard Space Flight Center},
title = {Algorithm for Compressing Time-Series Data},
year = {2012},
month = {June},
url = {https://www.techbriefs.com/component/content/article/13857-gsc-14820-1},
}
@article{smartgrid,
author = {Frank Eichinger and Pavel Efros and Stamatis Karnouskos and Klemens Böhm},
journal = {The VLDB Journal},
pages = {193-218},
title = {A time-series compression technique and its application to the smart grid},
volume = {24},
year = {2015},
url = {https://doi.org/10.1007/s00778-014-0368-8},
}
@techreport{flac,
author = {Martijn van Beurden and Andrew Weaver},
institution = {IETF},
title = {Free Lossless Audio Codec},
year = {2017},
month = {June},
url = {https://datatracker.ietf.org/doc/draft-ietf-cellar-flac/},
}
@techreport{microsoft,
author = {n. a.},
institution = {Microsoft},
title = {Azure Monitor Metrics aggregation and display explained},
year = {2023},
month = {June},
url = {https://learn.microsoft.com/en-us/azure/azure-monitor/essentials/metrics-aggregation-explained},
}
@InProceedings{10.1007/978-3-319-63712-9_8,
author="Peng, Xuesong
and Pernici, Barbara",
editor="Helfert, Markus
and Klein, Cornel
and Donnellan, Brian
and Gusikhin, Oleg",
title="Monitoring Data Reduction in Data Centers: A Correlation-Based Approach",
booktitle="Smart Cities, Green Technologies, and Intelligent Transport Systems",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="135--153",
abstract="Monitoring data are collected and stored in a wide range of domains, especially in data centers, which integrate myriads of services and massive data. To handle the inevitable challenges brought by increasing volume of monitoring data, this paper proposes a correlation-based reduction method for streaming data that derives quantitative formulas between correlated indicators, and reduces the sampling rate of some indicators by replacing them with formulas predictions. This approach also revises formulas through iterations of the reduction process to find an adaptive solution in dynamic environments of data centers. One highlight of this work is the ability to work on upstream side, i.e., it can reduce volume requirements for data collection of monitoring systems. This work also tests the approach with both simulated and real data, showing that our approach is capable of data reduction in complex data centers.",
isbn="978-3-319-63712-9"
}
@article{10.14778/2735479.2735481,
author = {Ding, Rui and Wang, Qiang and Dang, Yingnong and Fu, Qiang and Zhang, Haidong and Zhang, Dongmei},
title = {YADING: fast clustering of large-scale time series data},
year = {2015},
issue_date = {January 2015},
publisher = {VLDB Endowment},
volume = {8},
number = {5},
issn = {2150-8097},
url = {https://doi.org/10.14778/2735479.2735481},
doi = {10.14778/2735479.2735481},
abstract = {Fast and scalable analysis techniques are becoming increasingly important in the era of big data, because they are the enabling techniques to create real-time and interactive experiences in data analysis. Time series are widely available in diverse application areas. Due to the large number of time series instances (e.g., millions) and the high dimensionality of each time series instance (e.g., thousands), it is challenging to conduct clustering on large-scale time series, and it is even more challenging to do so in real-time to support interactive exploration.In this paper, we propose a novel end-to-end time series clustering algorithm, YADING, which automatically clusters large-scale time series with fast performance and quality results. Specifically, YADING consists of three steps: sampling the input dataset, conducting clustering on the sampled dataset, and assigning the rest of the input data to the clusters generated on the sampled dataset. In particular, we provide theoretical proof on the lower and upper bounds of the sample size, which not only guarantees YADING's high performance, but also ensures the distribution consistency between the input dataset and the sampled dataset. We also select L1 norm as similarity measure and the multi-density approach as the clustering method. With theoretical bound, this selection ensures YADING's robustness to time series variations due to phase perturbation and random noise.Evaluation results have demonstrated that on typical-scale (100,000 time series each with 1,000 dimensions) datasets, YADING is about 40 times faster than the state-of-the-art, sampling-based clustering algorithm DENCLUE 2.0, and about 1,000 times faster than DBSCAN and CLARANS. YADING has also been used by product teams at Microsoft to analyze service performance. Two of such use cases are shared in this paper.},
journal = {Proc. VLDB Endow.},
month = {jan},
pages = {473-484},
numpages = {12}
}
@misc{prometheus,
    author = "Prometheus Authors",
    title = "Prometheus - From metrics to insights",
    year = "2024",
    url = "https://prometheus.io/",
    note = "[Online; accessed 1-March-2024]"
}
@misc{cassandra,
    author = "The Apache Software Foundation",
    title = "Apache Cassandra - Open Source NoSQL Database",
    year = "2024",
    url = "https://cassandra.apache.org/_/index.html",
    note = "[Online; accessed 1-March-2024]"
}